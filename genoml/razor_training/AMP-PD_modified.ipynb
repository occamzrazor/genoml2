{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Logistic Regression on AMP-PD \n",
    "\n",
    "#### Author: Maria Castanos and William Koehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from logistic_regression import RazorLogReg\n",
    "from dimensionality_reduction import SelectFeatures\n",
    "from sklearn import model_selection\n",
    "import time\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from S3\n",
    "path = \"/Users/mdmcastanos/Documents/OccamzRazor/plink_files/\"\n",
    "numpy_file = path + \"plink_numpy.npy\"\n",
    "tsv_file = path + \"latest_labels.tsv\"\n",
    "y = pd.read_csv(tsv_file, sep = '\\t')\n",
    "df = pd.DataFrame(np.load(numpy_file))\n",
    "df = df.assign(participant_id=y[\"participant_id\"], case_control_other_latest = y['case_control_other_latest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing dataset to generate examples\n",
    "df = df[:][0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['case_control_other_latest'])\n",
    "y = df['case_control_other_latest']\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset has *x* features and *n* rows, the feature space was reduced by choosing the most relevant features according to different [feature selection methods](logistic_regression). \n",
    "\n",
    "### Tree-based Feature Selection\n",
    "Computes impurity-based feature importances to drop irrelevant features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Features\n",
    "selected_features = SelectFeatures()\n",
    "train_set_reduced = selected_features.get_reduced_dataset(X_train, y_train)\n",
    "test_set_reduced = selected_features.get_test_set_reduced(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "classifier1 = RazorLogReg(train_set_reduced, test_set_reduced)\n",
    "logistic_regression = classifier1.get_logistic_regression(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Tree-based Predictions\n",
    "log_reg_predicted_classes, log_reg_predicted_probs = classifier1.predict(logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Feature Selection\n",
    "This method chooses the best features based on univariate statistical tests. In this case, the ANOVA F-value is used to estimate the degree of linear dependency between two random variables (For different types of relationships mutual information methods can be used but I suspect there's not enough data to do that)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination with CV\n",
    "Since this algorithm eliminates the less significant variables from the fitted variables, as opposed to the previous seen methods, this method requires that we fit the model first and pass it as a parameter to the RFE algorithm. The cross validation is then done to fins the optimal value of features to be kept in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = SelectFeatures()\n",
    "\n",
    "# Train set set\n",
    "ID, X_train_rfecv, y_train_rfecv = selected_features.get_data(X_train, y_train)\n",
    "train_set_rfecv = pd.concat([ID.reset_index(drop=True), \n",
    "                                     y_train_rfecv.reset_index(drop=True), \n",
    "                                     X_train_rfecv.reset_index(drop=True)],\n",
    "                                    axis = 1, \n",
    "                                    ignore_index=False)\n",
    "\n",
    "# Test set set\n",
    "ID, X_test_rfecv, y_test_rfecv = selected_features.get_data(X_test, y_test)\n",
    "test_set_rfecv = pd.concat([ID.reset_index(drop=True), \n",
    "                                     y_test_rfecv.reset_index(drop=True), \n",
    "                                     X_test_rfecv.reset_index(drop=True)],\n",
    "                                    axis = 1, \n",
    "                                    ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "n = list(range(0, 50)) + [\"case_control_other_latest\", \"participant_id\"] # Reducing the data to generate examples\n",
    "classifier = RazorLogReg(train_set_rfecv[n], test_set_rfecv[n])\n",
    "logistic_regression_rfecv = classifier.logistic_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Features\n",
    "n = list(range(0, 50)) # Reducing the data to generate examples\n",
    "X_train_rfecv = X_train_rfecv[n]\n",
    "selector = RFECV(logistic_regression_rfecv, step=1, cv=3)\n",
    "logistic_regression_rfecv = selector.fit(X_train_rfecv, y_train_rfecv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RFECV predictions\n",
    "log_reg_rfecv_predicted_classes, log_reg_rfecv_predicted_probs = classifier.predict(logistic_regression_rfecv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Multinomial Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "A regularized multinomial logistic regression is trained to predict three classes (Control, Case, Other). Elastic Net penalization was used in order to compromise between ridge and lasso penalizations. \n",
    "\n",
    "The optimization problem is:\n",
    "$$\\max_{\\beta_{0k}, \\beta_{k}} \\left\\{ \\sum_{i = 1}^{N} \\log Pr(g_i|x_i) - \\lambda \\sum_{k = 1}^K\\sum_{j = 1}^p \\big(\\alpha |\\beta_{kj}| + (1 - \\alpha)\\beta_{kj}^2\\big) \\right\\}$$\n",
    "### Hyperparameter Optimization\n",
    "Hyperparameter $\\lambda$ in the optimization problem above, is optimized by implementing grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the performance of the logistic regression against baseline models, both a random and a majority-class classifers were trained. \n",
    "To evaluate the performance of the logistic regression, both a random and a majority-class classifers were implemented as baseline models to compare against. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "ID, X_train_bl, y_train_bl = selected_features.get_data(X_train, y_train)\n",
    "train_set_bl = pd.concat([ID.reset_index(drop=True), \n",
    "                          y_train_bl.reset_index(drop=True), \n",
    "                          X_train_bl.reset_index(drop=True)],\n",
    "                         axis = 1, \n",
    "                         ignore_index=False)\n",
    "\n",
    "# Test set set\n",
    "ID, X_test_bl, y_test_bl = selected_features.get_data(X_test, y_test)\n",
    "test_set_bl = pd.concat([ID.reset_index(drop=True), \n",
    "                         y_test_bl.reset_index(drop=True), \n",
    "                         X_test_bl.reset_index(drop=True)],\n",
    "                        axis = 1, \n",
    "                        ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RazorLogReg(train_set_bl, test_set_bl)\n",
    "random_classifier = classifier.get_random_classifier()\n",
    "majority_class_classifier = classifier.get_majority_class_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline models predictions\n",
    "rc_predicted_classes, rc_predicted_probs = classifier.predict(random_classifier)\n",
    "mc_predicted_classes, mc_predicted_probs = classifier.predict(majority_class_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Logistic Regression RFECV</th>\n",
       "      <th>Random Classifier</th>\n",
       "      <th>Majority Class Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.533</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.498</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.533</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.515</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  Logistic Regression RFECV  Random Classifier  \\\n",
       "Accuracy                 0.533                      0.400              0.567   \n",
       "Precision                0.498                      0.160              0.556   \n",
       "Recall                   0.533                      0.400              0.567   \n",
       "F1 Score                 0.515                      0.229              0.545   \n",
       "\n",
       "           Majority Class Classifier  \n",
       "Accuracy                       0.533  \n",
       "Precision                      0.284  \n",
       "Recall                         0.533  \n",
       "F1 Score                       0.371  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_table = classifier1.get_performance_table(logistic_regression)\n",
    "performance_table = pd.DataFrame(performance_table)\n",
    "\n",
    "performance_table['Logistic Regression RFECV'] = [metrics.accuracy_score(y_test_rfecv, log_reg_rfecv_predicted_classes),\n",
    "                                          metrics.precision_score(y_test_rfecv, log_reg_rfecv_predicted_classes, \n",
    "                                                                  average='weighted'),\n",
    "                                          metrics.recall_score(y_test_rfecv, log_reg_rfecv_predicted_classes,\n",
    "                                                               average='weighted'), \n",
    "                                          metrics.f1_score(y_test_rfecv, log_reg_rfecv_predicted_classes, \n",
    "                                                           average='weighted')]\n",
    "\n",
    "\n",
    "performance_table['Random Classifier'] = [metrics.accuracy_score(y_test_bl, rc_predicted_classes),\n",
    "                                          metrics.precision_score(y_test_bl, rc_predicted_classes, \n",
    "                                                                  average='weighted'),\n",
    "                                          metrics.recall_score(y_test_bl, rc_predicted_classes,\n",
    "                                                               average='weighted'), \n",
    "                                          metrics.f1_score(y_test_bl, rc_predicted_classes, \n",
    "                                                           average='weighted')]\n",
    "\n",
    "performance_table['Majority Class Classifier'] = [metrics.accuracy_score(y_test_bl, mc_predicted_classes),\n",
    "                                                  metrics.precision_score(y_test_bl, mc_predicted_classes, \n",
    "                                                                          average='weighted'), \n",
    "                                                  metrics.recall_score(y_test_bl, mc_predicted_classes, \n",
    "                                                                       average='weighted'), \n",
    "                                                  metrics.f1_score(y_test_bl, mc_predicted_classes, \n",
    "                                                                   average='weighted')]\n",
    "performance_table.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add PCA to the pipeline. \n",
    "- Implement univariate feature selection (Deal with current float error).\n",
    "- Literature review on different ways of training on Patient Data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
